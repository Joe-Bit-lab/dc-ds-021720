{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src= \"img_murat/bob_ross.jpg\" style=\"height:200px\">\n",
    "\n",
    "\n",
    "\n",
    "# Objectives\n",
    "\n",
    "- Describe decision tree methods for classification and regression.\n",
    "\n",
    "- Apply a decision tree regressor with sklearn.\n",
    "\n",
    "- Define Gini impurity index, Shannon's entropy.\n",
    "\n",
    "- Compare decision trees with the models we learnt before. \n",
    "\n",
    "## Introduction to trees\n",
    "\n",
    "[Goker Erdogan's repo](https://github.com/gokererdogan/JaverianaMLCourse/blob/master/Lectures/08.pdf)\n",
    "\n",
    "\n",
    "\n",
    "## Regression Trees \n",
    "[dataset](https://www.kaggle.com/floser/hitters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hits</th>\n",
       "      <th>Years</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81</td>\n",
       "      <td>14</td>\n",
       "      <td>475.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130</td>\n",
       "      <td>3</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141</td>\n",
       "      <td>11</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>91.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>169</td>\n",
       "      <td>11</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hits  Years  Salary\n",
       "1    81     14   475.0\n",
       "2   130      3   480.0\n",
       "3   141     11   500.0\n",
       "4    87      2    91.5\n",
       "5   169     11   750.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import baseball data and let's name it as hitters\n",
    "hitters = pd.read_csv('data/Hitters.csv')[['Hits', 'Years', 'Salary']]\n",
    "hitters.dropna(inplace  = True)\n",
    "hitters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitters.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"img_murat/hitters_salary2.png\" style=\"height:250px\">\n",
    "<img src= \"img_murat/partition_of_set.png\" style=\"height:250px\">\n",
    "img source: ISLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sklearn DecisionTreeRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hitters.Salary.apply(np.log)\n",
    "\n",
    "X = hitters.drop(columns= ['Salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 482020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# instantiate the DecisionTreeRegressor Class\n",
    "estimator = tree.DecisionTreeRegressor()\n",
    "#estimator - is an DecisionTreeRegressor object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the fit method to learn the splittings\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = estimator.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_pred - y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.881784197001252e-16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4263120398517007"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## R_2\n",
    "estimator.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test = mean_absolute_error(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_train = mean_absolute_error(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_train = mean_squared_error(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test = mean_squared_error(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6.163315\n",
       "2    6.173786\n",
       "Name: Salary, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Visualize a tree__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hitters.pdf'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz \n",
    "dot_data = tree.export_graphviz(estimator, out_file=None, \n",
    "                     feature_names=features,  \n",
    "                     filled=True, rounded=True,  \n",
    "                     special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph.render(\"Hitters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your Turn__\n",
    "\n",
    "- Use sklearn.tree to fit a DecisionTree (Hint: use DecisionTreeRegressor class)\n",
    "\n",
    "- This time don't let the tree grow very big. (This is called 'Pruning')\n",
    "\n",
    "- [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7460909379850235"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "estimator = tree.DecisionTreeRegressor(max_leaf_nodes= 10)\n",
    "\n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "estimator.score(X_train, y_train)\n",
    "\n",
    "# print the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6868415853965191"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Max_leave_nodes=10.pdf'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz \n",
    "dot_data = tree.export_graphviz(estimator, out_file=None, \n",
    "                     feature_names=features,  \n",
    "                     filled=True, rounded=True,  \n",
    "                     special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph.render(\"Max_leave_nodes=10\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that by default sklearn returns $R^{2}$-score. If we want we can use other metrics in sklearn too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  0.0027721772615634304\n",
      "Mean Absolute Error:  0.011524138096108048\n",
      "R_2:  0.9964804755929203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (mean_squared_error, mean_absolute_error) \n",
    "\n",
    "y_pred = estimator.predict(X)\n",
    "\n",
    "print('Mean Squared Error: ', mean_squared_error(y, y_pred))\n",
    "print('Mean Absolute Error: ', mean_absolute_error(y, y_pred))\n",
    "print('R_2: ', estimator.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use trained estimator for making predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is happening under the hood? \n",
    "\n",
    "- Divide the predictor space $X_1, X_2, \\cdots X_k$ into distinct rectangles $R_1, \\cdots, R_{k}$\n",
    "\n",
    "- For every observation that falls into the region $R_j$ , we make the same prediction, which is simply the mean of the response values for the training observations in $R_j$.\n",
    "\n",
    "__Obvious questions__\n",
    "\n",
    "- Why we divide rectangular regions?\n",
    "\n",
    "- How to construct rectangles $R_1, \\cdots, R_{j}$'s\n",
    "\n",
    "__Goal__\n",
    "\n",
    "Again we try to construct rectangles $R_j$ so that the residual suim of squares is minimum:\n",
    "\n",
    "<img src= \"img_murat/dt_least_square.png\" style=\"height:100px\">\n",
    "\n",
    "__Problem__ with this approach is too complicated to find!! \n",
    "\n",
    "__Solution?__ Greedy algorithm!!\n",
    "\n",
    "Instead of finding best partition, start from one variable and do the best partition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Final Algorithm__\n",
    " \n",
    "- Start with a variable and division that gives the greatest possible reduction in RSS\n",
    "\n",
    "- Continue this approach but only check the RSS in resulting regions.\n",
    "\n",
    "- Stop with a predetermined stopping criteria.\n",
    "\n",
    "<img src= \"img_murat/Partition_with_5_boxes_ISLR.png\" style=\"height:300px\">\n",
    "\n",
    "<img src= \"img_murat/graph_of_partition_with_5_boxes.png\" style=\"height:300px\">\n",
    "\n",
    "\n",
    "\n",
    "### Possible Problems:\n",
    "\n",
    "- Good for training but not for test --> Can you see why?\n",
    "\n",
    "- Overfitting is a common thing with decision trees: Solution is __Tree Pruning!__\n",
    "\n",
    "\n",
    "<img src= \"img_murat/pruning.jpg\" style=\"height:250px\">\n",
    "\n",
    "\n",
    "[Let's check sklearn for pruning methods!!](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
    "\n",
    "For more on Tree pruning read pg: 307 from ISLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = hitters.sort_values(by = 'Hits')\n",
    "X_sorted = df_sorted[['Years', 'Hits']]\n",
    "y_pred = estimator.predict(X_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_2 = tree.DecisionTreeRegressor(max_depth=2)\n",
    "\n",
    "est_2.fit(X, y)\n",
    "\n",
    "y_pred2 = est_2.predict(X_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize trees also within the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- years <= 4.50\n",
      "|   |--- hits <= 15.50\n",
      "|   |   |--- value: [7.24]\n",
      "|   |--- hits >  15.50\n",
      "|   |   |--- value: [5.06]\n",
      "|--- years >  4.50\n",
      "|   |--- hits <= 117.50\n",
      "|   |   |--- value: [6.00]\n",
      "|   |--- hits >  117.50\n",
      "|   |   |--- value: [6.74]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree.export import export_text\n",
    "\n",
    "r = export_text(est_2, feature_names= ['years', 'hits'])\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can save the graph as a pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baseball.pdf'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz \n",
    "dot_data = tree.export_graphviz(est_2, out_file=None, \n",
    "                     feature_names=['years', 'salary'],  \n",
    "                     filled=True, rounded=True,  \n",
    "                     special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph.render(\"baseball\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the classification metrics we will move to other notebook. But if you have time you can take a look at the rest of this notebook too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Trees\n",
    "\n",
    "\n",
    "Q: Can we use the same algorithm?\n",
    "\n",
    "Q1: What might go wrong?  Hint: RSS for classification?\n",
    "\n",
    "Q2: What else can we use for classification?\n",
    "\n",
    "### Classification Error Rate\n",
    "\n",
    "<img src= \"img_murat/classification_error_rate.png\" style=\"height:100px\">\n",
    "\n",
    "### Gini Index\n",
    "\n",
    "<img src= \"img_murat/gini.png\" style=\"height:100px\">\n",
    "\n",
    "### Shannon's Entropy\n",
    "\n",
    "<img src= \"img_murat/entropy.png\" style=\"height:100px\">\n",
    "\n",
    "### Comparison of different impurity costs:\n",
    "\n",
    "<img src= \"img_murat/gini_classification_entropy.png\" style=\"height:400px\">\n",
    "\n",
    "\n",
    "## Advantages of Tree Methods\n",
    "\n",
    "[Sklearn Documentation](https://scikit-learn.org/stable/modules/tree.html)\n",
    "\n",
    "<img src= \"img_murat/advantages_of_trees.png\" style=\"height:400px\">\n",
    "\n",
    "## Disadvantages of Tree Methods\n",
    "\n",
    "<img src= \"img_murat/disadvantages_of_trees.png\" style=\"height:200px\">\n",
    "\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "Q: what is information gain criteria? \n",
    "\n",
    "[Watch this video](https://www.youtube.com/watch?v=LDRbO9a6XPU)\n",
    "\n",
    "Q: What is ID3, C4.5 and CART?\n",
    "\n",
    "[sklearn documentation 1.10.6](https://scikit-learn.org/stable/modules/tree.html)\n",
    "\n",
    "Q: What are the tricky things that we should watch out in application?\n",
    "\n",
    "[sklearn documentation 1.10.5 - Tips on Practical Use](https://scikit-learn.org/stable/modules/tree.html)\n",
    "\n",
    "Q: Can sklearn plot the structure of a decision tree?\n",
    "\n",
    "[Check this blog? I didn't fully read this though](https://medium.com/@rnbrown/creating-and-visualizing-decision-trees-with-python-f8e8fa394176)\n",
    "\n",
    "More readings:\n",
    "\n",
    "[ISLR - Chapter 8](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf)\n",
    "\n",
    "[A 61 page chapter from a book. - Looks friendly :)](https://www-users.cs.umn.edu/~kumar001/dmbook/ch4.pdf)\n",
    "\n",
    "[What is the difference btwn 'mse' vs 'friedman_mse'](https://projecteuclid.org/euclid.aos/1013203451)\n",
    "\n",
    "[Categorical Variables with sklearn-trees](https://stackoverflow.com/questions/24715230/can-sklearn-random-forest-directly-handle-categorical-features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
